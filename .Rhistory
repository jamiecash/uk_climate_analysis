# Get data for all stations and append to data
num_rows <- nrow(table)
for (row in 1:num_rows) {
# Get the station name and URL of the stations data txt file
name <- table[row, "Name"]
url <- table[row, "station_data"]
# Check the text file to find where the header starts, then remove header row
# and rows prior to header row.
header_txt <- "   yyyy  mm   tmax    tmin      af    rain     sun"
text <- readLines(url, warn=FALSE)
header_row <- which(text==header_txt)
text <- text[-(0:header_row+1)]
# Remove all data after position 50 from every line. This may contain comments
# which we don't want to be parsed. We also need to add the last column if it
# is missing as  some lines are not formatted correctly
lines = str_split(text, '\n')
clean_text <- ""
for(n in 1:length(lines)) {
line <- lines[n][[1]] %>% substr(0, 50)
if (line != 'Site Closed' && line != 'Site closed') {
if(str_length(line) < 46) {
line <- paste(line, ' ---')
}
clean_text <- paste(clean_text, line, sep='\n')
}
}
clean_text <- clean_text[2:length(clean_text)]
# Read fixed length text into dataframe and set column names
station_data <- data.table::fread(text=clean_text)
colnames(station_data) <-
c("year", "month", "max_temp", "min_temp", "af_days", "rainfall", "sun_hours")
# Select only columns required for analysis and add station name
station_data$station_name <- name
station_data <- station_data %>% select(all_of(columns))
# Merge into main data frame
data <- rbind(data, station_data)
}
print(data)
# Create the dataframe
columns <- c("year", "month", "max_temp", "min_temp", "rainfall", "station_name")
data <- data.frame(matrix(nrow = 0, ncol = length(columns)))
colnames(data) <- columns
# Get data for all stations and append to data
num_rows <- nrow(table)
for (row in 1:num_rows) {
# Get the station name and URL of the stations data txt file
name <- table[row, "Name"]
url <- table[row, "station_data"]
# Check the text file to find where the header starts, then remove header row
# and rows prior to header row.
header_txt <- "   yyyy  mm   tmax    tmin      af    rain     sun"
text <- readLines(url, warn=FALSE)
header_row <- which(text==header_txt)
text <- text[-(0:header_row+1)]
# Remove all data after position 50 from every line. This may contain comments
# which we don't want to be parsed. We also need to add the last column if it
# is missing as  some lines are not formatted correctly
lines = str_split(text, '\n')
clean_text <- ""
for(n in 1:length(lines)) {
line <- lines[n][[1]] %>% substr(0, 50)
if (line != 'Site Closed' && line != 'Site closed') {
if(str_length(line) < 46) {
line <- paste(line, ' ---')
}
clean_text <- paste(clean_text, line, sep='\n')
}
}
clean_text <- clean_text[2:length(clean_text)]
# Read fixed length text into dataframe and set column names
station_data <- data.table::fread(text=clean_text)
colnames(station_data) <-
c("year", "month", "max_temp", "min_temp", "af_days", "rainfall", "sun_hours")
# Select only columns required for analysis and add station name
station_data$station_name <- name
station_data <- station_data %>% select(all_of(columns))
# Merge into main data frame
data <- rbind(data, station_data)
}
head(data)
url <-  "https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data"
webpage <- read_html(url)
table_nodes = html_nodes(webpage, "table")
# Get the HTML table
table <- table_nodes %>% html_table(trim=TRUE) %>% .[[1]]
# Get the links to the data for each station and add to the dataframe, then remove the 'Data' column which only contains the text 'View data'
station_data <- webpage %>% html_nodes(xpath = "//table//a") %>% html_attr("href")
table <- cbind(table, station_data)
table <- subset(table, select = -c(Data))
# Display the weather station names and URL to data
table %>% select(Name, station_data)
url <-  "https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data"
webpage <- read_html(url)
table_nodes = html_nodes(webpage, "table")
# Get the HTML table
table <- table_nodes %>% html_table(trim=TRUE) %>% .[[1]]
# Get the links to the data for each station and add to the dataframe, then remove the 'Data' column which only contains the text 'View data'
station_data <- webpage %>% html_nodes(xpath = "//table//a") %>% html_attr("href")
table <- cbind(table, station_data)
table <- subset(table, select = -c(Data))
# Display the weather station names and URL to data
table %>% select(Name, station_data)
# Get data for all stations and append to data
num_rows <- nrow(table)
# Create the dataframe
columns <- c("year", "month", "max_temp", "min_temp", "rainfall", "station_name")
data <- data.frame(matrix(nrow = 0, ncol = length(columns)))
colnames(data) <- columns
# Get data for all stations and append to data
num_rows <- nrow(table)
for (row in 1:num_rows) {
# Get the station name and URL of the stations data txt file
name <- table[row, "Name"]
url <- table[row, "station_data"]
# Check the text file to find where the header starts, then remove header row
# and rows prior to header row.
header_txt <- "   yyyy  mm   tmax    tmin      af    rain     sun"
text <- readLines(url, warn=FALSE)
header_row <- which(text==header_txt)
text <- text[-(0:header_row+1)]
# Remove all data after position 50 from every line. This may contain comments
# which we don't want to be parsed. We also need to add the last column if it
# is missing as  some lines are not formatted correctly
lines = str_split(text, '\n')
clean_text <- ""
for(n in 1:length(lines)) {
line <- lines[n][[1]] %>% substr(0, 50)
if (line != 'Site Closed' && line != 'Site closed') {
if(str_length(line) < 46) {
line <- paste(line, ' ---')
}
clean_text <- paste(clean_text, line, sep='\n')
}
}
clean_text <- clean_text[2:length(clean_text)]
# Read fixed length text into dataframe and set column names
station_data <- data.table::fread(text=clean_text)
colnames(station_data) <-
c("year", "month", "max_temp", "min_temp", "af_days", "rainfall", "sun_hours")
# Select only columns required for analysis and add station name
station_data$station_name <- name
station_data <- station_data %>% select(all_of(columns))
# Merge into main data frame
data <- rbind(data, station_data)
}
head(data)
url <-  "https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data"
webpage <- read_html(url)
table_nodes = html_nodes(webpage, "table")
# Get the HTML table
table <- table_nodes %>% html_table(trim=TRUE) %>% .[[1]]
# Get the links to the data for each station and add to the dataframe, then remove the 'Data' column which only contains the text 'View data'
station_data <- webpage %>% html_nodes(xpath = "//table//a") %>% html_attr("href")
table <- cbind(table, station_data)
table <- subset(table, select = -c(Data))
# Display the weather station names and URL to data
table %>% select(Name, station_data) %>% head()
# Create the dataframe
columns <- c("year", "month", "max_temp", "min_temp", "rainfall", "station_name")
data <- data.frame(matrix(nrow = 0, ncol = length(columns)))
colnames(data) <- columns
# Get data for all stations and append to data
num_rows <- nrow(table)
for (row in 1:num_rows) {
# Get the station name and URL of the stations data txt file
name <- table[row, "Name"]
url <- table[row, "station_data"]
# Check the text file to find where the header starts, then remove header row
# and rows prior to header row.
header_txt <- "   yyyy  mm   tmax    tmin      af    rain     sun"
text <- readLines(url, warn=FALSE)
header_row <- which(text==header_txt)
text <- text[-(0:header_row+1)]
# Remove all data after position 50 from every line. This may contain comments
# which we don't want to be parsed. We also need to add the last column if it
# is missing as  some lines are not formatted correctly
lines = str_split(text, '\n')
clean_text <- ""
for(n in 1:length(lines)) {
line <- lines[n][[1]] %>% substr(0, 50)
if (line != 'Site Closed' && line != 'Site closed') {
if(str_length(line) < 46) {
line <- paste(line, ' ---')
}
clean_text <- paste(clean_text, line, sep='\n')
}
}
clean_text <- clean_text[2:length(clean_text)]
# Read fixed length text into dataframe and set column names
station_data <- data.table::fread(text=clean_text)
colnames(station_data) <-
c("year", "month", "max_temp", "min_temp", "af_days", "rainfall", "sun_hours")
# Select only columns required for analysis and add station name
station_data$station_name <- name
station_data <- station_data %>% select(all_of(columns))
# Merge into main data frame
data <- rbind(data, station_data)
}
head(data)
unique(data$year)
unique(data$year)
unique(data$year)
min(year)
unique(data$year)
min(data$year)
max(data$year)
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
+   geom_bar(mapping = aes(x = month))
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
geom_bar(mapping = aes(x = month))
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
geom_bar(mapping = aes(x = month)) +
axis(1, at=month)
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
geom_bar(mapping = aes(x = month)) +
labs(title="Distribution of Weather Station Readings by Month",
x ="Month", y = "# Readings")
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
geom_bar(mapping = aes(x = month)) +
labs(title="Distribution of Weather Station Readings by Month",
y = "# Readings") +
scale_x_discrete(name ="Month", limits=unique(data$month))
unique(data$month)
min(data$month)
max(data$month)
ggplot(data = data) +
geom_bar(mapping = aes(x = month)) +
labs(title="Distribution of Weather Station Readings by Month",
y = "# Readings") +
scale_x_discrete(name ="Month", limits=c('Jan', 'Feb', 'Mar', 'Apr', 'May',
'Jun', 'Jul', 'Aug', 'Sep', 'Oct',
'Nov', 'Dec'))
unique(data$max_temp)
unique(data$max_temp)
min(data$max_temp)
max(data$max_temp)
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
unique(data$max_temp)
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
# Convert '---' to null
data$max_temp <- replace(data$max_temp, data$max_temp=='---', NULL)
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
# Convert '---' to null
data$max_temp <- null_if(data$max_temp, '---')
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
# Convert '---' to null
data$max_temp <- na_if(data$max_temp, '---')
unique(data$max_temp)
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
# Convert '---' to null
data$max_temp <- na_if(data$max_temp, '---')
# Convert to double
data$max_temp <- as_numeric(data$max_temp)
# Remove '*'s
data$max_temp <- gsub("\\*","",data$max_temp)
# Convert '---' to null
data$max_temp <- na_if(data$max_temp, '---')
# Convert to double
